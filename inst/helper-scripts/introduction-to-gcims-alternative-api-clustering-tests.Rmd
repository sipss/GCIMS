---
title: "Introduction to GCIMS, Alternative API"
output:
  "BiocStyle::pdf_document":
    df_print: "kable"
    dev: png
package: GCIMS
author: "GCIMS authors"
date: "`r format(Sys.Date(), '%F')`"
abstract: >
  An introduction to the GCIMS package, showing the most relevant functions and
  a proposed workflow. This includes loading demo samples, adding sample
  annotations, preprocessing the spectra, alignment, detecting peaks and regions
  of interest (ROIs), clustering of ROIs across samples, peak integration and
  building a peak table.
vignette: >
  %\VignetteIndexEntry{Introduction to GCIMS, Alternative API}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
start_time <- Sys.time()
library(BiocParallel)
library(ggplot2)
library(GCIMS)
```

The GCIMS package allows you to import your Gas Chromatography - Ion Mobility Spectrometry samples,
preprocess them, align them one to each other and build a peak table with the relevant features.

Enable parallellization of the workflow, here we use three cores:

```{r}
show_progress_bar <- interactive() && is.null(getOption("knitr.in.progress"))
# disable parallellization: (Useful for better error reporting)
register(SerialParam(progressbar = show_progress_bar), default = TRUE)
# enable parallellization with 3 workers (you can use more if you have them):
#register(SnowParam(workers = 3, progressbar = show_progress_bar, exportglobals = FALSE), default = TRUE)
```


This vignette will use a small dataset consisting of a mixture of three ketones.

# Downloading the dataset:

```{r}
# The folder where we will download the samples:
samples_directory <- "threeketones"

# Download the ketones dataset:
tryCatch({
  download_three_ketones_dataset(samples_directory)
  message("Download successful")
}, error = function(e) {
  message("The download of the samples did not succeed. Stopping")
  message(conditionMessage(e))
  knitr::knit_exit()
})
```

```{r}
# Check that the files are downloaded:
list.files(samples_directory)
```

# Import data

Please start by preparing an Excel spreadsheet (or a CSV/TSV file if you prefer)
with your samples and their annotations. Please name the first column `SampleID`
and the second column `Filename`. We will use those annotations in plots.



```{r message=FALSE}
annotations <- readr::read_csv(file.path(samples_directory, "annotations.csv"))
annotations
```

If you need to create your `annotations.csv` file for your samples, please
follow the example from `help("create_annotations_table")` for further details.

# Create a GCIMSDataset object

```{r}
dataset <- GCIMSDataset(
  annotations,
  base_dir = samples_directory,
  on_ram = TRUE # You probably should set this to FALSE if you have more 
                # than a handful of samples. See ?GCIMSDataset.
)
dataset
```


Most operations on the `dataset` are not executed until you need to get the actual samples or
data. This is done to perform them in batch, more efficiently, if possible. However,
you can manually `realize` the `GCIMSDataset` object so it executes all its pending operations.
We can see how the "read_sample" pending operation becomes part of the dataset history:

```{r}
realize(dataset)
dataset
```
Explore one sample:

```{r}
ket1 <- getSample(dataset, sample = "Ketones1")
plotRaw(ket1, rt_range = c(0, 1000), dt_range = c(7.5, 17))
```

```{r}
dt_k1 <- dtime(ket1)
tis_k1 <- getTIS(ket1)

ggplot(dplyr::filter(data.frame(x = dt_k1, y = tis_k1), x >1)) + 
  geom_line(aes(x = x, y = y)) +
  scale_x_continuous(name = "Drift time (ms)", limits = c(7, 17)) +
  scale_y_continuous(name = "Intensity (a.u)", trans = cubic_root_trans())
```


```{r}
rt_k1 <- rtime(ket1)
ric_k1 <- getRIC(ket1)

ggplot(dplyr::filter(data.frame(x = rt_k1, y = ric_k1))) + 
  geom_line(aes(x = x, y = y)) +
  scale_x_continuous(name = "Retention time (ms)", limits = c(55, 900)) +
  scale_y_continuous(name = "Intensity (a.u)")
```

Plot the RIC and the TIS to get an overview of the dataset:

```{r}
plotTIS(dataset)
```

```{r}
plotRIC(dataset)
```


# Filter the retention and drift time of your samples

```{r}
filterRt(dataset, rt = c(0, 1300)) # in s
filterDt(dataset, dt = c(1, 17)) # in ms
dataset
```



```{r}
ket1afterfilter <- getSample(dataset, sample = "Ketones1")
ket1afterfilter
```

# Smoothing

You can remove noise from your sample using a Savitzky-Golay filter, applied
both in drift time and in retention time.

The Savitzky-Golay has two main parameters: the filter length and the filter order.
It is recommended to use a filter order of 2, but the filter length must be selected
so it is large enough to remove noise but always smaller than the peak width to
prevent distorting the peaks.

You can apply the smoothing filter to a single IMS spectrum or to a single chromatogram
to see how noise is removed and how peaks are not distorted. Tweak the filter lengths
and, once you are happy, apply the smoothing filter to all the dataset.

```{r smoothing-starts-here}
one_ims_spec <- getSpectrum(ket1afterfilter, rt_range = 97.11)
```

```{r}
one_ims_smoothed <- smooth(one_ims_spec, dt_length_ms = 0.14, dt_order = 2)
to_plot <- dplyr::bind_rows(
  NoSmoothed = as.data.frame(one_ims_spec),
  Smoothed = as.data.frame(one_ims_smoothed),
  .id = "Status"
)
ggplot(to_plot) +
  geom_line(aes(x = drift_time_ms, y = intensity, colour = Status)) +
  coord_cartesian(xlim = c(7, 10)) +
  labs(x = "Drift time (ms)", y = "Intensity (a.u.)")
ggplot(to_plot) +
  geom_line(aes(x = drift_time_ms, y = intensity, colour = Status)) +
  coord_cartesian(xlim = c(7, 10), ylim = c(0, 300)) +
  labs(x = "Drift time (ms)", y = "Intensity (a.u.)")
```

```{r}
one_chrom <- getChromatogram(ket1afterfilter, dt_range = 10.4)
```

```{r}
one_chrom_smoothed <- smooth(one_chrom, rt_length_s = 3, rt_order = 2)
to_plot <- dplyr::bind_rows(
  NoSmoothed = as.data.frame(one_chrom),
  Smoothed = as.data.frame(one_chrom_smoothed),
  .id = "Status"
)
ggplot(to_plot) +
  geom_line(aes(x = retention_time_s, y = intensity, colour = Status)) +
  labs(x = "Retention time (s)", y = "Intensity (a.u.)")
ggplot(to_plot) +
  geom_line(aes(x = retention_time_s, y = intensity, colour = Status)) +
  coord_cartesian(xlim = c(200, 250)) +
  labs(x = "Retention time (s)", y = "Intensity (a.u.)")
```

You can also apply it to a single sample:

```{r}
ket1_smoothed <- smooth(
  ket1afterfilter,
  rt_length_s = 3,
  dt_length_ms = 0.14,
  rt_order = 2,
  dt_order = 2
)
```

```{r}
cowplot::plot_grid(
  plotRaw(ket1afterfilter, rt_range = c(0, 500), dt_range = c(6, 16)),
  plotRaw(ket1_smoothed, rt_range = c(0, 500), dt_range = c(6, 16)),
  ncol = 2
)
```



Or to the whole dataset (the default order is 2 for both axes):

```{r}
dataset <- smooth(dataset, rt_length_s = 3, dt_length_ms = 0.14)
realize(dataset)
```

# Decimation



One way to speed up calculations and reduce the memory requirements is to decimate
the matrix, by taking 1 every Nd points in drift time and 1 every Nr points in retention time.

```{r}
ket1_decimated <- decimate(ket1_smoothed, rt_factor = 1, dt_factor = 2)
```

```{r}
ket1_spec_smoothed <- getSpectrum(ket1_smoothed, rt_range = 300, dt_range = c(7, 13))
ket1_spec_decimated <- getSpectrum(ket1_decimated, rt_range = 300, dt_range = c(7, 13))
```

```{r}
cowplot::plot_grid(
  plot(ket1_spec_smoothed) + labs(title = "Before decimation"),
  plot(ket1_spec_decimated) + labs(title = "After decimation"),
  ncol = 1
)

```


Once you are satisfied with de decimation factor (if you want to apply it) just
use it on the whole dataset:

```{r}
dataset <- decimate(dataset, rt_factor = 1, dt_factor = 2)
```

One alternative is to start with a higher decimation factor (lets say
2 in retention time and 4 in drift time) and, after running the pipeline successfully,
repeat it without decimation.




# Alignment

Pressure and temperature fluctuations as well as degradation of the chromatographic
column are some of the causes of misalignments in the data, both in retention and
drift time.

In order to be able to compare samples to each other, we align the samples.

The alignment will happen first in drift time and afterwards in retention time. To
correct the drift time, we will use a multiplicative correction $t_d' = k  t_d$. The
correction factor $k$ will be estimated using the RIP positions for each sample,
extracted from the Total Ion Spectra. The correction factors are typically between
0.9 and 1.1. The reference RIP position is the median of all the RIP positions to
minimize the distortions.

One of the checks to verify the alignment in drift time is not failing is by plotting
the Total Ion Spectra of several samples before and after the alignment and see
the effect of the correction.

The retention time will be corrected using Parametric Time Warping, where
$t_r' = P(t_r)$, and $P$ is a polynomial of typically not a high order (1-5). For
efficiency reasons, the polynomial will be estimated using the Reverse Ion Chromatogram of
the samples to be aligned.



```{r}
plotTIS(dataset, dt_range = c(7, 17))
```

```{r}
plotRIC(dataset)
```


```{r alignment-starts-here}
align(dataset)
```

```{r}
realize(dataset)
```

```{r}
plotTIS(dataset, dt_range = c(7, 17))
```

```{r}
plotRIC(dataset)
```



```{r fig.height=8}
align_plots <- alignPlots(dataset)
cowplot::plot_grid(plotlist = align_plots, ncol = 2)
```




# Peaks


First try one sample and optimize the `noise_level` parameter there. Change values
from 0.5 to 4 to explore. If it's higher less peaks will be found. If it is too low
peaks may appear broken into two regions or false detections may occur.

```{r peak-detection-starts-here}
ket1 <- getSample(dataset, "Ketones1")
ket1 <- findPeaks(
  ket1,
  noise_level = 3,
  rt_length_s = 3,
  dt_length_ms = 0.14,
  verbose = TRUE,
  iou_overlap_threshold = 0.2
)
peak_list_ket1 <- peaks(ket1)
plt <- plotRaw(ket1)
plt <- add_peaklist_rect(plt, peak_list_ket1, color_by = "PeakID")
plt + guides(color = "none")
```


```{r}
# 1. Data load
int_mat <- intensity(ket1)
spec_length <- nrow(int_mat)
num_spec <- ncol(int_mat)

# Compute the 2nd derivative for both axes
deriv2 <- GCIMS:::compute_second_deriv(
  int_mat,
  dt_length_pts = 11L,
  rt_length_pts = 21L,
  dt_order = 2L,
  rt_order = 2L
)
drt <- -deriv2$drt
ddt <- -deriv2$ddt
rm(deriv2)
```

```{r}
GCIMS:::mat_to_gplot(
  drt,
  dt_min = dtime(ket1)[1],
  dt_max = dtime(ket1)[nrow(drt)],
  rt_min = rtime(ket1)[1],
  rt_max = rtime(ket1)[ncol(drt)]
)
```

```{r}
GCIMS:::mat_to_gplot(
  ddt,
  dt_min = dtime(ket1)[1],
  dt_max = dtime(ket1)[nrow(ddt)],
  rt_min = rtime(ket1)[1],
  rt_max = rtime(ket1)[ncol(ddt)]
)
```

# 1460, 175
```{r}
region10 <- GCIMS:::find_region_without_peaks(int_mat, half_min_size = c(10, 10), noise_quantile = 0.25)
sigmaNoise_drt <- stats::sd(drt[region10$row_min:region10$row_max, region10$col_min:region10$col_max])
sigmaNoise_ddt <- stats::sd(ddt[region10$row_min:region10$row_max, region10$col_min:region10$col_max])
print(sigmaNoise_drt)
print(sigmaNoise_ddt)

```

```{r}
region50 <- GCIMS:::find_region_without_peaks(int_mat, half_min_size = c(50, 50), noise_quantile = 0.25)
sigmaNoise_drt <- stats::sd(drt[region50$row_min:region50$row_max, region50$col_min:region50$col_max])
sigmaNoise_ddt <- stats::sd(ddt[region50$row_min:region50$row_max, region50$col_min:region50$col_max])
print(sigmaNoise_drt)
print(sigmaNoise_ddt)

```


```{r}
MassSpecWavelet::peakDetectionCWT(ddt[,250], scales = c(1, 32,64))$majorPeakInfo$peakIndex
```


```{r}
plot(dtime(ket1), ddt[,30], type = "l")
```

```{r}
prof <- profvis::profvis({
  start <- Sys.time()
  
  prep_wav <- MassSpecWavelet::prepareWavelets(ncol(drt), scales = c(1, 32, 48, 64))
  peaks_and_zeros_drt <- purrr::map_dfr(seq_len(nrow(drt)), function(dt_idx) {
    peak_idx <- unname(MassSpecWavelet::peakDetectionCWT(ms = drt[dt_idx,], prep_wav, exclude0scaleAmpThresh = TRUE)$majorPeakInfo$peakIndex)
    zero_idx <- GCIMS:::findZeroCrossings(drt[dt_idx,])
    if (length(peak_idx) == 0 || length(zero_idx) == 0) {
      return(
        tibble::tibble(
          dt_idx_apex = integer(0L),
          rt_idx_apex = integer(0L),
          is_rt_peak = logical(0L),
          rt_idx_min = integer(0L),
          rt_idx_max = integer(0L)
        )
      )
    }
    out <- tibble::tibble(
      dt_idx_apex = rep(dt_idx, length(peak_idx)),
      rt_idx_apex = peak_idx,
      rt_idx_min = NA_integer_,
      rt_idx_max = NA_integer_
    )
    zero_idx2 <- 1L
    for (i in seq_len(nrow(out))) {
      if (out$rt_idx_apex[i] <= zero_idx[1L]) {
        next
      }
      while (out$rt_idx_apex[i] >= zero_idx[zero_idx2]) {
        zero_idx2 <- zero_idx2 + 1L
      }
      if (zero_idx2 > length(zero_idx)) {
        break
      }
      out$rt_idx_min[i] <- zero_idx[zero_idx2 - 1L]
      out$rt_idx_max[i] <- zero_idx[zero_idx2]
    }
    out <- dplyr::filter(out, !is.na(.data$rt_idx_min))
    out <- out[, c("dt_idx_apex", "rt_idx_apex", "rt_idx_min", "rt_idx_max")]
    out
  })
  
  prep_wav <- MassSpecWavelet::prepareWavelets(nrow(ddt), scales = c(1, 32, 48, 64))
  peaks_and_zeros_ddt <- purrr::map_dfr(seq_len(ncol(ddt)), function(rt_idx) {
    peak_idx <- unname(MassSpecWavelet::peakDetectionCWT(ms = ddt[,rt_idx], prep_wav, exclude0scaleAmpThresh = TRUE)$majorPeakInfo$peakIndex)
    zero_idx <- GCIMS:::findZeroCrossings(ddt[,rt_idx])
    if (length(peak_idx) == 0 || length(zero_idx) == 0) {
      return(
        tibble::tibble(
          dt_idx_apex = integer(0L),
          rt_idx_apex = integer(0L),
          dt_idx_min = integer(0L),
          dt_idx_max = integer(0L)
        )
      )
    }
    out <- tibble::tibble(
      dt_idx_apex = peak_idx,
      rt_idx_apex = rep(rt_idx, length(peak_idx)),
      dt_idx_min = NA_integer_,
      dt_idx_max = NA_integer_
    )
    zero_idx2 <- 1L
    for (i in seq_len(nrow(out))) {
      if (out$dt_idx_apex[i] <= zero_idx[1L]) {
        next
      }
      while (out$dt_idx_apex[i] >= zero_idx[zero_idx2]) {
        zero_idx2 <- zero_idx2 + 1L
      }
      if (zero_idx2 > length(zero_idx)) {
        break
      }
      out$dt_idx_min[i] <- zero_idx[zero_idx2 - 1L]
      out$dt_idx_max[i] <- zero_idx[zero_idx2]
    }
    out <- dplyr::filter(out, !is.na(.data$dt_idx_min))
    out <- out[, c("dt_idx_apex", "rt_idx_apex", "dt_idx_min", "dt_idx_max")]
    out
  })
  
  
  ROIs <- dplyr::inner_join(
    peaks_and_zeros_drt,
    peaks_and_zeros_ddt,
    by = c("dt_idx_apex", "rt_idx_apex")
  )
  ROIs <- ROIs[, c("dt_idx_min", "dt_idx_max", "rt_idx_min", "rt_idx_max", "dt_idx_apex", "rt_idx_apex"), drop = FALSE]
  
  spent <- Sys.time() - start
  print(spent)
})

```

```{r}
overlapPercentage <- function(ROI1, ROI2){
  if (
    ROI1$dt_idx_min >= ROI2$dt_idx_max ||
    ROI1$dt_idx_max <= ROI2$dt_idx_min ||
    ROI1$rt_idx_min >= ROI2$rt_idx_max ||
    ROI1$rt_idx_max <= ROI2$rt_idx_min) {
    return(0.0)
  }
  area1 <- (ROI1$dt_idx_max - ROI1$dt_idx_min)*(ROI1$rt_idx_max - ROI1$rt_idx_min)
  area2 <- (ROI2$dt_idx_max - ROI2$dt_idx_min)*(ROI2$rt_idx_max - ROI2$rt_idx_min)
  x_left <- max(ROI1$dt_idx_min, ROI2$dt_idx_min)
  y_top <- min(ROI1$rt_idx_max, ROI2$rt_idx_max)
  x_right <- min(ROI1$dt_idx_max, ROI2$dt_idx_max)
  y_bottom <- max(ROI1$rt_idx_min, ROI2$rt_idx_min)
  overlapping_area <- (x_right - x_left)*(y_top - y_bottom)
  p <- overlapping_area / (area1 + area2 - overlapping_area)
  return(p)
}
merge_overlapping_rois <- function(ROIs, int_mat, iou_overlap_threshold) {
  if (iou_overlap_threshold > 1) {
    return(ROIs)
  }

  if (nrow(ROIs) >= 1) {
    aff <- seq_len(nrow(ROIs))

    done <- NULL
    for (j in seq_len(nrow(ROIs) - 1L)) {
      done <- c(done, j)
      R1 <- as.list(ROIs[j, ])
      for (k in seq.int(from = j + 1L, to = nrow(ROIs))) {
        R2 <- as.list(ROIs[k, ])
        if (aff[k] != j) {
          if (abs(overlapPercentage(R1, R2)) > iou_overlap_threshold) {
            aff[aff == k] <- j
          }
        }
      }
    }
  }


  labels <- unique(aff)
  ROIs_overlap <- tibble::tibble(
    dt_idx_min = integer(length(labels)),
    dt_idx_max = integer(length(labels)),
    rt_idx_min = integer(length(labels)),
    rt_idx_max = integer(length(labels)),
    dt_idx_apex = integer(length(labels)),
    rt_idx_apex = integer(length(labels))
  )

  for (n in seq_along(labels)) {
    idx <- which(aff == labels[n])
    R1 <- as.list(ROIs[idx[1], ])
    if (length(idx) > 1) {
      for (m in 2:length(idx)) {
        R2 <- as.list(ROIs[idx[m], ])
        r1_int_apex <- int_mat[R1$dt_idx_apex, R1$rt_idx_apex]
        r2_int_apex <- int_mat[R2$dt_idx_apex, R2$rt_idx_apex]
        if (r1_int_apex >= r2_int_apex) {
          dt_idx_apex <- R1$dt_idx_apex
          rt_idx_apex <- R1$rt_idx_apex
        } else {
          dt_idx_apex <- R2$dt_idx_apex
          rt_idx_apex <- R2$rt_idx_apex
        }

        R1 <- list(
          dt_idx_min = min(R1$dt_idx_min, R2$dt_idx_min),
          dt_idx_max = max(R1$dt_idx_max, R2$dt_idx_max),
          rt_idx_min = min(R1$rt_idx_min, R2$rt_idx_min),
          rt_idx_max = max(R1$rt_idx_max, R2$rt_idx_max),
          dt_idx_apex = dt_idx_apex,
          rt_idx_apex = rt_idx_apex
        )
      }
    }
    ROIs_overlap$dt_idx_min[n] <- R1$dt_idx_min
    ROIs_overlap$dt_idx_max[n] <- R1$dt_idx_max
    ROIs_overlap$rt_idx_min[n] <- R1$rt_idx_min
    ROIs_overlap$rt_idx_max[n] <- R1$rt_idx_max
    ROIs_overlap$dt_idx_apex[n] <- R1$dt_idx_apex
    ROIs_overlap$rt_idx_apex[n] <- R1$rt_idx_apex
  }
  return(ROIs_overlap)
}

```


```{r}
compute_center_of_mass <- function(ROIs, int_mat) {
  ROIs$dt_cm_idx <- NA_integer_
  ROIs$rt_cm_idx <- NA_integer_
  for (i in seq_len(nrow(ROIs))) {
    patch <- int_mat[
      ROIs$dt_idx_min[i]:ROIs$dt_idx_max[i],
      ROIs$rt_idx_min[i]:ROIs$rt_idx_max[i],
      drop = FALSE
    ]

    # roi center of mass
    v <- rowSums(patch)
    dt_cm1 <- (sum(v * seq_along(v)) / sum(v)) + ROIs$dt_idx_min[i]  - 1L
    v <- colSums(patch)
    rt_cm1 <- (sum(v * seq_along(v)) / sum(v)) + ROIs$rt_idx_min[i] - 1L
    ROIs$rt_cm_idx[i] <- round(rt_cm1)
    ROIs$dt_cm_idx[i] <- round(dt_cm1)
  }
  ROIs
}
```

```{r}
rois_to_peaklist <- function(ROIs, drift_time, retention_time, int_mat, ddt, drt) {
  fmt <- paste0("%0", nchar(as.character(nrow(ROIs))), "d")
  peak_list <- tibble::tibble(
    PeakID = sprintf(fmt, seq_len(nrow(ROIs))),
    dt_apex_ms = NA_real_,
    rt_apex_s = NA_real_,
    int_apex_au = purrr::map_dbl(
      seq_len(nrow(ROIs)), 
      function(j) {
        int_mat[ROIs$dt_idx_apex[j], ROIs$rt_idx_apex[j]]
      }
    ),
    ddt_apex_au = purrr::map_dbl(
      seq_len(nrow(ROIs)), 
      function(j) {
        ddt[ROIs$dt_idx_apex[j], ROIs$rt_idx_apex[j]]
      }
    ),
    drt_apex_au = purrr::map_dbl(
      seq_len(nrow(ROIs)), 
      function(j) {
        drt[ROIs$dt_idx_apex[j], ROIs$rt_idx_apex[j]]
      }
    ),
    dt_min_ms = NA_real_,
    dt_max_ms = NA_real_,
    rt_min_s = NA_real_,
    rt_max_s = NA_real_,
    dt_cm_ms = NA_real_,
    rt_cm_s = NA_real_,
    dt_apex_idx = ROIs$dt_idx_apex,
    rt_apex_idx = ROIs$rt_idx_apex,
    dt_min_idx = ROIs$dt_idx_min,
    dt_max_idx = ROIs$dt_idx_max,
    rt_min_idx = ROIs$rt_idx_min,
    rt_max_idx = ROIs$rt_idx_max,
    dt_cm_idx = ROIs$dt_cm_idx,
    rt_cm_idx = ROIs$rt_cm_idx
  )
  peak_list <- dplyr::mutate(
    peak_list,
    dt_apex_ms = .env$drift_time[.data$dt_apex_idx],
    rt_apex_s = .env$retention_time[.data$rt_apex_idx],
    dt_min_ms = .env$drift_time[.data$dt_min_idx],
    dt_max_ms = .env$drift_time[.data$dt_max_idx],
    rt_min_s = .env$retention_time[.data$rt_min_idx],
    rt_max_s = .env$retention_time[.data$rt_max_idx],
    dt_cm_ms = .env$drift_time[.data$dt_cm_idx],
    rt_cm_s = .env$retention_time[.data$rt_cm_idx]
  )
  peak_list
}
```



```{r}
ROIs_overlap <- merge_overlapping_rois(ROIs, int_mat, iou_overlap_threshold = 0.2)
# Compute ROI's center of mass:
ROIs_overlap_cm <- compute_center_of_mass(ROIs = ROIs_overlap, int_mat = int_mat)
# Convert into a data frame / peak list:
peak_list <- rois_to_peaklist(
  ROIs = ROIs_overlap_cm,
  drift_time = dtime(ket1),
  retention_time = rtime(ket1),
  int_mat = int_mat,
  ddt = ddt,
  drt = drt
)

```


```{r}
plt <- plotRaw(ket1)
plt <- add_peaklist_rect(plt, peak_list)
plt
```

```{r}

```



# ¿Qué estrategias hay?

## Referencia

- Celia usando el VOCal crea una peak table


## Para hacer clustering



## Para medir que el clustering funciona




- Luis propone filtrar la lista de picos por intensidad


# Listar problemas por severidad


# Al respecto de la presencia de picos de contaminación tenemos los blancos.



# Como sabemos si un pico/roi es bueno?

-

# Como sabemos si un cluster es bueno?

- Tamaño de los clusters
- Numero de picos de la misma muestra en un cluster
- Picos fuera de la ROI del cluster
- ROI consenso: Coordenadas medianas


- ROIs que contienen al pico
- Centroide del cluster



- Dentro de cluster hay picos fuera del roi consenso (outlier):


  * [SI] sigmanoise por derivada parcial
  * [SI] ROI consenso: Mediana de la distancia del apice al borde
    para tener un tamaño mediano...
  * Criterio para el numero de clusters es:
  * Métrica del tamaño de la region
    del cluster. (max-min) * (max-min) o IQR * IQR
    percentil-95.
  * El tamaño de la dispersión de los apices que pertenecen a un cluster deberia
    ser menor al tamaño del roi consenso en ambas direcciones.
  * Porcentaje de missing data en funcion de N.



    + Coherencia entre clusters Jaccard.
    + Silouhette plot.
    + Densidad de cuantas muestras haya en cada cluster.
    + Complementariedad de clusters para detectar clusters que se han partidoh

  * iou < 0.2

  * peak_apex > 2consensusrois de distancia

 * Cuartear el plano dt x rt.



Then do it on the whole dataset:

```{r}
findPeaks(
  dataset,
  noise_level = 3,
  rt_length_s = 3,
  dt_length_ms = 0.14,
  iou_overlap_threshold = 0.2
)
peak_list <- peaks(dataset)
```
You can get any other sample if you like, plot it and plot its peaks on top:

```{r}
ket2 <- getSample(dataset, "Ketones2")
```


```{r}
plt <- plotRaw(ket2)
plt <- add_peaklist_rect(plt, peaks(ket2))
plt + lims(x= c(7.5,15), y = c(0, 500))
```



Or plot all the peaks from all the dataset together, overlayed on a single sample:

```{r}
plt <- plotRaw(ket2)
plt <- add_peaklist_rect(plt, peaks(dataset), color_by = "SampleID")
plt
```

# Clustering

## Kmedioids

```{r kmedoids-clustering-section-starts-here}
peak_clustering <- clusterPeaks(
  peak_list,
  distance_method = "sd_scaled_euclidean",
  clustering = list(method = "kmedoids", Nclusters = 13)
)
```

The peak list, with cluster ids can be plotted on top of a single sample:

```{r}
peak_list_clustered <- peak_clustering$peak_list_clustered
```


FIXME: We need a proper API to plot this with a user friendly interface, but we
can easily see there is some trouble with the clustering as of today (I'm working on it).

```{r fig.height=10, fig.width=10}
plt <- plotRaw(ket2)
plt <- add_peaklist_rect(plt, peak_list_clustered, color_by = "SampleID") + 
  lims(x = c(NA_real_, NA_real_), y = c(NA_real_, NA_real_)) +
  facet_wrap(~cluster, scales = "free")
plt
```

## Hierarchical clustering:


```{r hierarchi-clustering-section-starts-here}
peak_clustering_kmed <- clusterPeaks(
  peak_list,
  distance_method = "sd_scaled_euclidean",
  clustering = list(
    method = "kmedoids",
    Nclusters = 50
  ),
  verbose = TRUE
)
```

```{r}
plt <- plotRaw(ket2)
plt <- add_peaklist_rect(plt, peak_clustering_kmed$peak_list_clustered, color_by = "cluster") + guides(color=FALSE) +
  lims(x = c(7.5, 15), y = c(0, 500))
plt
```

```{r fig.height=5, fig.width=10}
silhouette <- peak_clustering_kmed$extra_clustering_info$silhouette
plot(x = silhouette, main = "Silhouette")
```



```{r}
peak_clustering_hclust <- clusterPeaks(
  peak_list,
  distance_method = "sd_scaled_euclidean",
  clustering = list(method = "hclust", method = "complete"),
  verbose = TRUE
)
```


```{r hclust2-clustering-section-starts-here}
peak_clustering_hclust2 <- clusterPeaks(
  peak_list,
  distance_method = "sd_scaled_euclidean",
  clustering = list(
    method = "hclust2",
    method = "complete",
    dt_ms_max_dist_thres = 0.58*3,
    rt_s_max_dist_thres = 28*3
  ),
  verbose = TRUE
)
```

```{r}
peak_clustering_hclust2$extra_clustering_info$num_cluster_estimation$rt_plot$layers[[4]]$data$xintercept <- NA_real_
```

```{r}
peak_clustering_hclust2$extra_clustering_info$num_cluster_estimation$rt_plot$layers[[4]]$data$xintercept <- 40
```


```{r}
peak_clustering_hclust2$extra_clustering_info$num_cluster_estimation$rt_plot
```


```{r}
#peak_clustering_hclust2$extra_clustering_info$num_cluster_estimation$dt_plot
```



```{r}
plt <- plotRaw(ket2)
plt <- add_peaklist_rect(plt, peak_clustering_hclust2$peak_list_clustered, color_by = "cluster") + guides(color=FALSE) +
  lims(x = c(7.5, 15), y = c(0, 500))
plt
```


```{r}
plt + lims(y = c(0, 200), x = c(7.5, 15))
```


```{r fig.height=10, fig.width=10}
plt <- plotRaw(ket2)
plt <- add_peaklist_rect(plt, peak_clustering_hclust2$peak_list_clustered, color_by = "SampleID") + 
  lims(x = c(NA_real_, NA_real_), y = c(NA_real_, NA_real_)) +
  facet_wrap(~cluster, scales = "free")
plt
```


```{r}
peak_clustering_hclust2$extra_clustering_info$num_cluster_estimation$rt_plot
```

```{r}
#peak_clustering_hclust2$extra_clustering_info$num_cluster_estimation$dt_plot
```

The resulting cluster sizes (median position of individual clusters) is not a good reference
for integration. We are working on this.

```{r}
plt <- plotRaw(ket2)
plt <- add_peaklist_rect(plt, peak_clustering$cluster_stats, color_by = "cluster")
plt
```

# Baseline correction

```{r baseline-section-starts-here}
ket1 <- getSample(dataset, "Ketones1")
```


```{r}
one_ims_spec <- getSpectrum(ket1, rt_range = 97.11)
```

```{r}
plot(one_ims_spec) + coord_cartesian(xlim = c(7, 12))
```

```{r}
one_ims_spec <- estimateBaseline(one_ims_spec, dt_peak_fwhm_ms = 0.2, dt_region_multiplier = 12)
to_plot <- data.frame(
  drift_time_ms = dtime(one_ims_spec),
  Intensity = intensity(one_ims_spec),
  Baseline = baseline(one_ims_spec)
)
ggplot(to_plot) +
  geom_line(aes(x = drift_time_ms, y = Intensity), color = "red") +
  geom_line(aes(x = drift_time_ms, y = Baseline), color = "blue") +
  labs(x = "Drift time (ms)", y = "Intensity (a.u.)")
ggplot(to_plot) +
  geom_line(aes(x = drift_time_ms, y = Intensity), color = "red") +
  geom_line(aes(x = drift_time_ms, y = Baseline), color = "blue") +
  coord_cartesian(xlim = c(7, 10), ylim = c(0, 500)) +
  labs(x = "Drift time (ms)", y = "Intensity (a.u.)")
```


```{r}
one_chrom <- getChromatogram(ket1, dt_range = 10.4)
```

```{r}
one_chrom <- estimateBaseline(one_chrom, rt_length_s = 200)
to_plot <- data.frame(
  retention_time_s = rtime(one_chrom),
  Intensity = intensity(one_chrom),
  Baseline = baseline(one_chrom)
)

ggplot(to_plot) +
  geom_line(aes(x = retention_time_s, y = Intensity), color = "red") +
  geom_line(aes(x = retention_time_s, y = Baseline), color = "blue") +
  labs(x = "Retention time (s)", y = "Intensity (a.u.)")
```

You can also apply it to a single sample:

```{r}
ket1 <- estimateBaseline(
  ket1,
  dt_peak_fwhm_ms = 0.2, 
  dt_region_multiplier = 12,
  rt_length_s = 200
)
```


```{r}
plotRaw(ket1)
```

```{r}
plotRaw(ket1, remove_baseline = TRUE)
```

```{r}
cowplot::plot_grid(
  plotRaw(ket1, rt_range = c(0, 500), dt_range = c(6, 16)),
  plotRaw(ket1, rt_range = c(0, 500), dt_range = c(6, 16), remove_baseline = TRUE),
  ncol = 2
)
```


Or to the whole dataset:

```{r}
dataset <- estimateBaseline(
  dataset,
  dt_peak_fwhm_ms = 0.2, 
  dt_region_multiplier = 12,
  rt_length_s = 200
)
realize(dataset)
```


```{r fig.height=10, fig.width=10}
plt <- plotRaw(ket2)
plt <- add_peaklist_rect(
  plt, 
  dplyr::filter(peak_clustering$peak_list_clustered),
  color_by = "SampleID",
  col_prefix = "fixedsize_"
) + 
  lims(x = c(NA_real_, NA_real_), y = c(NA_real_, NA_real_)) +
  facet_wrap(~cluster, scales = "free")
plt
```




# Peak integration

```{r}
dataset <- integratePeaks(
  dataset, 
  peak_clustering$peak_list, 
  integration_size_method = "fixed_size", 
  rip_saturation_threshold = 0.1
)
```



```{r}
peak_list <- peaks(dataset)
```


# Build peak table

```{r}
peak_table <- peakTable(peak_list, aggregate_conflicting_peaks = max)
peak_table$peak_table_matrix
```

# Imputation


```{r}
peak_table_imputed <- imputePeakTable(peak_table$peak_table_matrix, dataset, peak_clustering$cluster_stats)
peak_table_imputed
```

```{r}
# Implemented until here
end_time <- Sys.time()
message("The vignette ran in  ", format(end_time - start_time))
```


# Session Info:

```{r}
sessionInfo()
```

