---
title: "Introduction to GCIMS, Alternative API"
output: BiocStyle::pdf_document
package: GCIMS
author: "GCIMS authors"
date: "`r format(Sys.Date(), '%F')`"
abstract: >
  An introduction to the GCIMS package, showing the most relevant functions and
  a proposed workflow. This includes loading demo samples, adding sample
  annotations, preprocessing the spectra, alignment, detecting peaks and regions
  of interest (ROIs), clustering of ROIs across samples, peak integration and
  building a peak table.
vignette: >
  %\VignetteIndexEntry{Introduction to GCIMS, Alternative API}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(BiocParallel)
library(ggplot2)
library(GCIMS)
```

The GCIMS package allows you to import your Gas Chromatography - Ion Mobility Spectrometry samples,
preprocess them, align them one to each other and build a peak table with the relevant features.

This vignette will use a small dataset consisting of a mixture of three ketones.

# Downloading the dataset:

```{r}
# The folder where we will download the samples:
samples_directory <- "threeketones"

# Download the ketones dataset:
tryCatch({
  download_three_ketones_dataset(samples_directory)
}, error = function(e) {
  message("The download of the samples did not succeed. The vignette can't continue.")
  message(conditionMessage(e))
  knitr::knit_exit()
})
```

```{r}
# Check that the files are downloaded:
list.files(samples_directory)
```

Enable parallellization of the workflow, here we use three cores:

```{r}
# disable parallellization: (Useful for better error reporting)
register(SerialParam(progressbar = TRUE), default = TRUE)
# enable parallellization with 3 workers:
#register(SnowParam(workers = 3, progressbar = TRUE, exportglobals = FALSE), default = TRUE)
```

# Import data

Please start by preparing an Excel spreadsheet (or a CSV/TSV file if you prefer)
with your samples and their annotations. Please name the first column `SampleID`
and the second column `Filename`. We will use those annotations in plots.

```{r}
annotations <- readr::read_csv(file.path(samples_directory, "annotations.csv"), show_col_types = FALSE)
annotations
```

If you have some samples and you want to create your annotations file, you can use
the following code to create a template that you can fill with Excel:

```{r eval=FALSE}
# Your samples match this extension:
samples_ext <- "*.mea.gz"

filenames <- list.files(samples_directory, pattern = utils::glob2rx(samples_ext),
                        recursive = TRUE, include.dirs = FALSE)
#
annotations_template <- data.frame(
  SampleID = tools::file_path_sans_ext(filenames, compression = TRUE),
  FileName = filenames
)
# You may need to run: install.packages("writexl")
writexl::write_xlsx(annotations_template, file.path(samples_directory, "annotations.xlsx"))
```

You will find the `annotations.xlsx` file that you can edit and change at will.
Once you are happy with the annotations, you can load them back here with:

```{r eval=FALSE}
annotations <- readxl::read_excel(file.path(samples_directory, "annotations.xlsx"))
annotations
```

# Create a GCIMSDataset object

```{r}
# Delete the intermediate_files directory, if it exists
if (dir.exists("intermediate_files")) {
  unlink("intermediate_files", recursive = TRUE)
}
```


```{r}
dataset <- GCIMSDataset(annotations, base_dir = samples_directory, scratch_dir = "intermediate_files")
dataset
```

Most operations on the `dataset` are not executed until you need to get the actual samples or
data. This is done to perform them in batch, more efficiently, if possible. However,
you can manually `realize` the `GCIMSDataset` object so it executes all its pending operations.
We can see how the "read_sample" pending operation becomes part of the dataset history:

```{r}
realize(dataset)
dataset
```


Explore one sample:

```{r}
ket1 <- getGCIMSSample(dataset, sample = "Ketones1")
plotRaw(ket1, rt_range = c(0, 1000), dt_range = c(7.5, 17))
```


Plot the RIC and the TIS to get an overview of the dataset:


```{r}
plotTIS(dataset)
```

```{r}
plotRIC(dataset)
```


# Filter the retention and drift time of your samples

```{r}
filterRt(dataset, rt = c(0, 1300)) # in s
filterDt(dataset, dt = c(1, 17)) # in ms
dataset
```



```{r}
ket1afterfilter <- getGCIMSSample(dataset, sample = "Ketones1")
ket1afterfilter
```

# Smoothing

You can remove noise from your sample using a Savitzky-Golay filter, applied
both in drift time and in retention time.

The Savitzky-Golay has two main parameters: the filter length and the filter order.
It is recommended to use a filter order of 2, but the filter length must be selected
so it is large enough to remove noise but always smaller than the peak width to
prevent distorting the peaks.

You can apply the smoothing filter to a single IMS spectrum or to a single chromatogram
to see how noise is removed and how peaks are not distorted. Tweak the filter lengths
and, once you are happy, apply the smoothing filter to all the dataset.

```{r}
one_ims_spec <- getIMS(ket1afterfilter, rt_range = 97.11)
```

```{r}
one_ims_smoothed <- smooth(one_ims_spec, dt_length_ms = 0.14, dt_order = 2)
to_plot <- dplyr::bind_rows(
  NoSmoothed = as.data.frame(one_ims_spec),
  Smoothed = as.data.frame(one_ims_smoothed),
  .id = "Status"
)
ggplot(to_plot) +
  geom_line(aes(x = drift_time_ms, y = intensity, colour = Status)) +
  coord_cartesian(xlim = c(7, 10))
ggplot(to_plot) +
  geom_line(aes(x = drift_time_ms, y = intensity, colour = Status)) +
  coord_cartesian(xlim = c(7, 10), ylim = c(0, 300))
```

```{r}
one_chrom <- getEIC(ket1afterfilter, dt_range = 10.4)
```

```{r}
one_chrom_smoothed <- smooth(one_chrom, rt_length_s = 3, rt_order = 2)
to_plot <- dplyr::bind_rows(
  NoSmoothed = as.data.frame(one_chrom),
  Smoothed = as.data.frame(one_chrom_smoothed),
  .id = "Status"
)
ggplot(to_plot) +
  geom_line(aes(x = retention_time_s, y = intensity, colour = Status))
ggplot(to_plot) +
  geom_line(aes(x = retention_time_s, y = intensity, colour = Status)) +
  coord_cartesian(xlim = c(200, 250))
```


```{r}
knitr::knit_exit()
```

You can also apply it to a single sample:

```{r}
ket1_smoothed <- smooth(ket1afterfilter, rt_length_s = 3, dt_length_ms = 0.14, rt_order = 2, dt_order = 2)
```

```{r}
cowplot::plot_grid(
  plotRaw(ket1afterfilter, rt_range = c(0, 500), dt_range = c(6, 16)),
  plotRaw(ket1_smoothed, rt_range = c(0, 500), dt_range = c(6, 16)),
  ncol = 2
)
```



Or to the whole dataset (the default order is 2 for both axes):

```{r}
dataset <- smooth(dataset, rt_length_s = 3, dt_length_ms = 0.14)
dataset
```

```{r}
realize(dataset)
dataset
```


# Decimation

```{r}
knit_exit()
# The rest is not yet implemented
```


One way to speed up calculations and reduce the memory requirements is to decimate
the matrix, by taking 1 every Nd points in drift time and 1 every Nr points in retention time.

```{r}
ket1_decimated <- decimate(ket1_smoothed, rt_factor = 1, dt_factor = 2)
```

```{r}
ket1_spec_smoothed <- getEIS(ket1_smoothed, rtrange = 300, dtrange = c(7, 13))
ket1_spec_decimated <- getEIS(ket1_decimated, rtrange = 300, dtrange = c(7, 13))
```

```{r}
cowplot::plot_grid(
  plot(ket1_spec_smoothed) + labs(title = "Before decimation"),
  plot(ket1_spec_decimated) + labs(title = "After decimation"),
  ncol = 1
)

```

Once you are satisfied with de decimation factor (if you want to apply it) just
use it on the whole dataset:

```{r}
dataset <- decimate(dataset, rt_factor = 1, dt_factor = 2)
```

One alternative is to start with a higher decimation factor (lets say
2 in retention time and 4 in drift time) and, after running the pipeline successfully,
repeat it without decimation.


# Alignment

Pressure and temperature fluctuations as well as degradation of the chromatographic
column are some of the causes of misalignments in the data, both in retention and
drift time.

In order to be able to compare samples to each other, we align the samples.

The alignment will happen first in drift time and afterwards in retention time. To
correct the drift time, we will use a multiplicative correction $t_d' = k  t_d$. The
correction factor $k$ will be estimated using the RIP positions for each sample,
extracted from the Total Ion Spectra. The correction factors are typically between
0.9 and 1.1. The reference RIP position is the median of all the RIP positions to
minimize the distortions.

One of the checks to verify the alignment in drift time is not failing is by plotting
the Total Ion Spectra of several samples before and after the alignment and see
the effect of the correction.

The retention time will be corrected using Parametric Time Warping, where
$t_r' = P(t_r)$, and $P$ is a polynomial of typically not a high order (1-5). For
efficiency reasons, the polynomial will be estimated using the Reverse Ion Chromatogram of
the samples to be aligned.

```{r}
dataset <- computeTIS(dataset)
dataset <- computeRIC(dataset)
```


```{r}
tis_matrix <- getTIS(dataset)
ric_matrix <- getRIC(dataset)
```

```{r}
#plot matrices
# compute alignment corrections
# align dataset
# computeTIS and RIC
# compare tis and ric before and after
# plot two samples before and after
```

# Peaks

```{r}
peak_list <- peaks(dataset)
```

```{r}
# Shows all ROIs one on top of another (geom_rect, alpha...)
plotAllROIs(peak_list)
```

```{r}
# Plots a grid of 5 rows and 2 columns.
# Column 1 is intensity vs drift time
# Column 2 is intensity vs retention time
# Row 1 is when the ROI starts
# Row 3 is at the ROI apex
# Row 5 is when the ROI ends
# plotROI(dataset, peak_list[2,])
```

# Clustering

API to be decided:

```{r}
peak_clustering <- group_peak_list(
  peak_list,
  distance_method = "sd_scaled_euclidean",
  clustering = list(method = "kmedoids", Nclusters = 13)
)
```

```{r}
peak_list_clustered <- peak_clustering$peak_list_clustered
```

```{r}
peak_clustering$cluster_stats
```


## Refine clusters

- ROIs Fusion: gcims_rois_fusion

```{r}
# ROIs Fusion
fusion_res <- gcims_rois_fusion(
  peak_clustering$peak_list_clustered,
  peak_clustering$cluster_stats
)

ggplot() +
  geom_rect(
    data = dplyr::filter(fusion_res$peak_list_clustered, cluster == "Cluster07"),
    mapping = aes(
      xmin=ref_roi_dt_min_idx,
      xmax=ref_roi_dt_max_idx,
      ymin=ref_roi_rt_min_idx,
      ymax=ref_roi_rt_max_idx,
      fill = SampleID,
      color = SampleID
    ),
    alpha=0.5
  ) +
  labs(x = "Drift time (index)", "Retention time (index)", title = "Cluster07")
```


# Baseline correction


```{r}
dataset <- estimateBaseline(dataset)
```


```{r}
# Plot some spectrum before and after
# The API should be similar to smooth() (can be used on dataset, sample, EIC, EIS)
```


# Peak integration

```{r}
peak_list <- peakIntegration(dataset, fusion_res$peak_list, fusion_res$cluster_stats)
```

# Build peak table

```{r}
peak_table <- peakTable(peak_list, aggregate_conflicting_peaks = max)
peak_table$peak_table_matrix
```


# Imputation

```{r}
peak_table_imputed <- impute(peak_table, dataset, cluster_stats)
```

# Univariate analysis

e.g. Wilcoxon test with Benjamini-Hochberg

# Multivariate analysis

e.g. PLS-DA

# Session Info:

```{r}
sessionInfo()
```


